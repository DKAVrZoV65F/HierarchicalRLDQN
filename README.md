# Hierarchical RL + DQN

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)

## Описание

**Hierarchical RL + DQN** — это реализация иерархического обучения с подкреплением с использованием Deep Q-Network (DQN). Проект направлен на изучение подходов иерархического обучения с подкреплением для решения задач с длинными горизонтами и сложными структурами.

## Структура проекта

- **grid_world_rl/**: Содержит реализацию среды "Grid World" для тестирования алгоритмов RL.
- **utils/**: Вспомогательные функции и утилиты для обучения и оценки моделей.
- **main.py**: Главный скрипт для запуска обучения и тестирования модели.
- **requirements.txt**: Файл с перечнем необходимых зависимостей для проекта.

## Установка

1. Клонируйте репозиторий:

   ```bash
   git clone https://github.com/DKAVrZoV65F/hierarchical-rl-dqn.git
   ```

2. Перейдите в директорию проекта:

   ```bash
   cd hierarchical-rl-dqn
   ```

3. Создайте и активируйте виртуальное окружение:

   ```bash
   python -m venv env
   source env/bin/activate  # Для Windows: env\Scripts\activate
   ```

4. Установите зависимости:

   ```bash
   pip install -r requirements.txt
   ```

## Использование

Для запуска обучения модели выполните:

```bash
python main.py
```

Подробности настройки и запуска находятся в файле `main.py`. Вы можете изменять параметры обучения, среды и другие настройки в этом файле.

## Визуализация результатов

После обучения модели результаты можно визуализировать с помощью утилит из директории `utils/`. Например, для отображения графиков вознаграждений используйте:

```bash
python utils/plot_rewards.py
```
